{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e924a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057e507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "tf.random.set_seed(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ac3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 200\n",
    "batch_size = 50 # увеличьте значение для ускорения обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910ab2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5b8e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 тренировочные последовательности\n",
      "25000 тестовые последовательности\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'тренировочные последовательности')\n",
    "print(len(x_test), 'тестовые последовательности')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f611ae90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 200)\n",
      "x_test shape: (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d01116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построение модели...\n"
     ]
    }
   ],
   "source": [
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0, recurrent_dropout=0))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb548baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1774320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения...\n",
      "Epoch 1/3\n",
      "500/500 [==============================] - 103s 204ms/step - loss: 0.3959 - accuracy: 0.8200 - val_loss: 0.3443 - val_accuracy: 0.8486\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 107s 213ms/step - loss: 0.2946 - accuracy: 0.8800 - val_loss: 0.3174 - val_accuracy: 0.8661\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 105s 210ms/step - loss: 0.2183 - accuracy: 0.9131 - val_loss: 0.3287 - val_accuracy: 0.8676\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.3287 - accuracy: 0.8676\n",
      "Результат при тестировании: 0.3287259042263031\n",
      "Тестовая точность: 0.8675600290298462\n"
     ]
    }
   ],
   "source": [
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "904acc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4eba96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# построчное чтение из примера с текстом \n",
    "with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set(text)\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e3f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d065473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 50, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5acfd413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel_Nazarenko\\AppData\\Local\\Temp\\ipykernel_3096\\1321165275.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
      "C:\\Users\\Pavel_Nazarenko\\AppData\\Local\\Temp\\ipykernel_3096\\1321165275.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa246bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
    "NUM_ITERATIONS = 2\n",
    "NUM_EPOCHS_PER_ITERATION = 10\n",
    "NUM_PREDS_PER_EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "519b80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89346dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/10\n",
      "1241/1241 [==============================] - 64s 48ms/step - loss: 2.2988\n",
      "Epoch 2/10\n",
      "1241/1241 [==============================] - 59s 48ms/step - loss: 1.9113\n",
      "Epoch 3/10\n",
      "1241/1241 [==============================] - 59s 47ms/step - loss: 1.7509\n",
      "Epoch 4/10\n",
      "1241/1241 [==============================] - 58s 47ms/step - loss: 1.6435\n",
      "Epoch 5/10\n",
      "1241/1241 [==============================] - 58s 47ms/step - loss: 1.5623\n",
      "Epoch 6/10\n",
      "1241/1241 [==============================] - 57s 46ms/step - loss: 1.4977\n",
      "Epoch 7/10\n",
      "1241/1241 [==============================] - 57s 46ms/step - loss: 1.4454\n",
      "Epoch 8/10\n",
      "1241/1241 [==============================] - 57s 46ms/step - loss: 1.4013\n",
      "Epoch 9/10\n",
      "1241/1241 [==============================] - 57s 46ms/step - loss: 1.3638\n",
      "Epoch 10/10\n",
      "1241/1241 [==============================] - 57s 46ms/step - loss: 1.3315\n",
      "Генерация из посева:  her chin upon alices shoulder, and it was an unco\n",
      " her chin upon alices shoulder, and it was an uncourted to be and project gutenberg literary archive foundation in a little should be say in a little should be say in a little should be say in a little should be say in a little should be say in a lit==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/10\n",
      "1241/1241 [==============================] - 54s 43ms/step - loss: 1.3034\n",
      "Epoch 2/10\n",
      "1241/1241 [==============================] - 55s 44ms/step - loss: 1.2778\n",
      "Epoch 3/10\n",
      "1241/1241 [==============================] - 55s 44ms/step - loss: 1.2549\n",
      "Epoch 4/10\n",
      "1241/1241 [==============================] - 54s 43ms/step - loss: 1.2336\n",
      "Epoch 5/10\n",
      "1241/1241 [==============================] - 54s 44ms/step - loss: 1.2141\n",
      "Epoch 6/10\n",
      "1241/1241 [==============================] - 54s 44ms/step - loss: 1.1971\n",
      "Epoch 7/10\n",
      "1241/1241 [==============================] - 54s 44ms/step - loss: 1.1814\n",
      "Epoch 8/10\n",
      "1241/1241 [==============================] - 55s 44ms/step - loss: 1.1653\n",
      "Epoch 9/10\n",
      "1241/1241 [==============================] - 55s 44ms/step - loss: 1.1506\n",
      "Epoch 10/10\n",
      "1241/1241 [==============================] - 54s 44ms/step - loss: 1.1373\n",
      "Генерация из посева: tters it how far we go? his scaly friend replied. \n",
      "tters it how far we go? his scaly friend replied. the mock turtle said in a little shore and the white rabbit when it was so now and then and donations that the mouse of the state of course, and the mock turtle she was and distribution of the state o\n"
     ]
    }
   ],
   "source": [
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):k\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bad873",
   "metadata": {},
   "source": [
    "1) Лучше использовать 3 эпохи, дает самый точный результат. Увеличение количества нейронов в слое и добавление слоев не помогло улучшить качество. Удаление параметров dropout и recurrent_dropout увеличило точность. увеличение длины текста maxlen  и уменьшение max_features тоже улучшило качество "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113d224",
   "metadata": {},
   "source": [
    "2) На качество сильно влияют объем исходного текста (чем больше текст тем точнее), длина отсеченной фразы (чем длиннее - тем более точный текст), количество итераций и количество эпох. Последний абзац первое предложение еще можно додумать, но чтобы более точный текст выходил нужно еще больше факторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d6acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
